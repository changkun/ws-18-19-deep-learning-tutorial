{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR10 Competition\n",
    "\n",
    "CIFAR10 is a public dataset.\n",
    "It consists of 60000 32x32 colour images in 10 classes, with 6000 images per class (https://www.cs.toronto.edu/~kriz/cifar.html).\n",
    "\n",
    "The task of this competition is basically to create a model for a classifier that predicts the classes.\n",
    "This notebook contains a baseline model that you have to beat.\n",
    "If you are able to beat the baseline, you may submit your model such that you can compete with your classmates.\n",
    "\n",
    "Let's start with setting up the project.\n",
    "First, we load the dataset and pre-process it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.5390625 -0.515625  -0.5078125]\n",
      "  [-0.6640625 -0.640625  -0.6484375]\n",
      "  [-0.609375  -0.625     -0.6640625]\n",
      "  ...\n",
      "  [ 0.234375   0.03125   -0.15625  ]\n",
      "  [ 0.1875    -0.0234375 -0.203125 ]\n",
      "  [ 0.15625   -0.03125   -0.1953125]]\n",
      "\n",
      " [[-0.875     -0.84375   -0.84375  ]\n",
      "  [-1.        -1.        -1.       ]\n",
      "  [-0.859375  -0.9375    -1.       ]\n",
      "  ...\n",
      "  [-0.0390625 -0.3125    -0.5703125]\n",
      "  [-0.0703125 -0.3515625 -0.609375 ]\n",
      "  [-0.046875  -0.3203125 -0.5546875]]\n",
      "\n",
      " [[-0.8046875 -0.8125    -0.8359375]\n",
      "  [-0.875     -0.9453125 -1.       ]\n",
      "  [-0.6171875 -0.7890625 -0.9375   ]\n",
      "  ...\n",
      "  [-0.078125  -0.34375   -0.609375 ]\n",
      "  [-0.0625    -0.34375   -0.609375 ]\n",
      "  [-0.1484375 -0.4296875 -0.671875 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.625      0.328125  -0.25     ]\n",
      "  [ 0.5703125  0.1953125 -0.734375 ]\n",
      "  [ 0.546875   0.2578125 -0.796875 ]\n",
      "  ...\n",
      "  [ 0.25       0.0390625 -0.453125 ]\n",
      "  [-0.5625    -0.7578125 -0.9453125]\n",
      "  [-0.5859375 -0.734375  -0.84375  ]]\n",
      "\n",
      " [[ 0.40625    0.0859375 -0.25     ]\n",
      "  [ 0.3515625 -0.0390625 -0.671875 ]\n",
      "  [ 0.453125   0.125     -0.765625 ]\n",
      "  ...\n",
      "  [ 0.4375     0.15625   -0.265625 ]\n",
      "  [-0.2421875 -0.515625  -0.734375 ]\n",
      "  [-0.3515625 -0.5859375 -0.734375 ]]\n",
      "\n",
      " [[ 0.3828125  0.125     -0.09375  ]\n",
      "  [ 0.3125     0.0078125 -0.265625 ]\n",
      "  [ 0.3984375  0.109375  -0.3203125]\n",
      "  ...\n",
      "  [ 0.6875     0.4375     0.09375  ]\n",
      "  [ 0.1796875 -0.078125  -0.34375  ]\n",
      "  [-0.0390625 -0.28125   -0.4375   ]]]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# preprocess data\n",
    "x_train = ((x_train-128.)/128.).astype(np.float32)\n",
    "x_test = ((x_test-128.)/128.).astype(np.float32)\n",
    "\n",
    "y_train = (np.arange(10) == y_train[:]).astype(np.float32)\n",
    "y_test = (np.arange(10) == y_test[:]).astype(np.float32)\n",
    "\n",
    "print(x_train[0])\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function will be used to train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x, y, model, epochs=15, batch_size=1024):\n",
    "    cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=y) )\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "    correct = tf.equal(tf.argmax(model, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "\n",
    "    y_pred = tf.one_hot(tf.argmax(model, 1), int(model.shape[1]))\n",
    "    TP = tf.count_nonzero(y_pred * y)\n",
    "    TN = tf.count_nonzero((y_pred - 1) * (y - 1))\n",
    "    FP = tf.count_nonzero(y_pred * (y - 1))\n",
    "    FN = tf.count_nonzero((y_pred - 1) * y)\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.initializers.global_variables())\n",
    "        #sess.run(tf.local_variables_initializer())\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            def run_epoch():\n",
    "                epoch_loss = 0\n",
    "                for batch in range(x_train.shape[0]//batch_size):\n",
    "                    X, Y = x_train[batch*batch_size:(batch+1)*batch_size], y_train[batch*batch_size:(batch+1)*batch_size]\n",
    "                    _, c = sess.run([optimizer, cost], feed_dict={x:X, y:Y})\n",
    "                    epoch_loss += c\n",
    "                print(\"Epoch %d / %d completed. Loss: %.3f\" % (epoch+1, epochs, epoch_loss))\n",
    "            %time run_epoch()\n",
    "        \n",
    "            # compute measures:\n",
    "            print(\"accuracy %.4f, precision %.4f, recall %.4f, f1 %.4f\"\n",
    "                  % tuple(sess.run([accuracy, precision, recall, f1], {x:x_test, y:y_test})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define x and y placeholders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder('float', [None, 32, 32, 3])\n",
    "y = tf.placeholder('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function creates the baseline model.\n",
    "Do not add a softmax layer at the end, since it will be done by the softmax_cross_entropy_with_logits_v2 function later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model(x, classes=10):\n",
    "    # first reshape the input to a 2d image\n",
    "    x = tf.reshape(x, shape=[-1, 32, 32, 3])\n",
    "    \n",
    "    w = tf.Variable(tf.random_normal([5,5,3,16])) # [filter_height, filter_width, in_channels, out_channels]\n",
    "    conv1 = tf.nn.conv2d(x, w, strides=[1,1,1,1], padding='SAME')\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "    conv1 = tf.nn.max_pool(conv1, ksize=[1,5,5,1], strides=[1,1,1,1], padding='SAME')\n",
    "    \n",
    "    w = tf.Variable(tf.random_normal([5,5,16,32])) # [filter_height, filter_width, in_channels, out_channels]\n",
    "    conv2 = tf.nn.conv2d(conv1, w, strides=[1,1,1,1], padding='SAME')\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "    conv2 = tf.nn.max_pool(conv2, ksize=[1,5,5,1], strides=[1,1,1,1], padding='SAME')\n",
    "    \n",
    "    w = tf.Variable(tf.random_normal([5,5,32,64])) # [filter_height, filter_width, in_channels, out_channels]\n",
    "    conv3 = tf.nn.conv2d(conv2, w, strides=[1,1,1,1], padding='SAME')\n",
    "    conv3 = tf.nn.relu(conv3)\n",
    "    conv3 = tf.nn.max_pool(conv2, ksize=[1,5,5,1], strides=[1,1,1,1], padding='SAME')\n",
    "    \n",
    "    # we need to flatten / reshape the output of the cnn\n",
    "    cnn_neurons = int(np.prod(conv3.shape[1:]))\n",
    "    hidden_fc_neurons = 512\n",
    "    w = tf.Variable(tf.random_normal([cnn_neurons,hidden_fc_neurons]))\n",
    "    bias = tf.Variable(tf.random_normal([hidden_fc_neurons]))\n",
    "    fc = tf.reshape(conv3, [-1, cnn_neurons])\n",
    "    fc = tf.matmul(fc, w)\n",
    "    fc = fc + bias\n",
    "    fc = tf.nn.relu(fc)\n",
    "    \n",
    "    w = tf.Variable(tf.random_normal([hidden_fc_neurons, classes]))\n",
    "    bias = tf.Variable(tf.random_normal([classes]))\n",
    "    output = tf.matmul(fc, w) + bias\n",
    "    # softmax activation will be done by softmax_cross_entropy_with_logits_v2\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell you can train the baseline model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 15 completed. Loss: 4609251.324\n",
      "CPU times: user 16min 53s, sys: 1min 13s, total: 18min 7s\n",
      "Wall time: 2min 45s\n",
      "accuracy 0.2793, precision 0.2793, recall 0.2793, f1 0.2793\n",
      "Epoch 2 / 15 completed. Loss: 1679893.369\n",
      "CPU times: user 16min 50s, sys: 1min 14s, total: 18min 4s\n",
      "Wall time: 2min 46s\n",
      "accuracy 0.3286, precision 0.3286, recall 0.3286, f1 0.3286\n",
      "Epoch 3 / 15 completed. Loss: 1244279.779\n",
      "CPU times: user 16min 54s, sys: 1min 14s, total: 18min 8s\n",
      "Wall time: 2min 44s\n",
      "accuracy 0.3616, precision 0.3616, recall 0.3616, f1 0.3616\n",
      "Epoch 4 / 15 completed. Loss: 1033437.229\n",
      "CPU times: user 16min 55s, sys: 1min 13s, total: 18min 8s\n",
      "Wall time: 2min 43s\n",
      "accuracy 0.3867, precision 0.3867, recall 0.3867, f1 0.3867\n",
      "Epoch 5 / 15 completed. Loss: 889568.027\n",
      "CPU times: user 16min 58s, sys: 1min 14s, total: 18min 12s\n",
      "Wall time: 2min 42s\n",
      "accuracy 0.4010, precision 0.4010, recall 0.4010, f1 0.4010\n",
      "Epoch 6 / 15 completed. Loss: 779708.188\n",
      "CPU times: user 16min 56s, sys: 1min 14s, total: 18min 10s\n",
      "Wall time: 2min 43s\n",
      "accuracy 0.4114, precision 0.4114, recall 0.4114, f1 0.4114\n",
      "Epoch 7 / 15 completed. Loss: 692333.221\n",
      "CPU times: user 16min 56s, sys: 1min 13s, total: 18min 10s\n",
      "Wall time: 2min 42s\n",
      "accuracy 0.4194, precision 0.4194, recall 0.4194, f1 0.4194\n",
      "Epoch 8 / 15 completed. Loss: 623555.010\n",
      "CPU times: user 16min 54s, sys: 1min 14s, total: 18min 8s\n",
      "Wall time: 2min 44s\n",
      "accuracy 0.4269, precision 0.4269, recall 0.4269, f1 0.4269\n",
      "Epoch 9 / 15 completed. Loss: 564613.837\n",
      "CPU times: user 16min 41s, sys: 1min 14s, total: 17min 55s\n",
      "Wall time: 2min 45s\n",
      "accuracy 0.4267, precision 0.4267, recall 0.4267, f1 0.4267\n",
      "Epoch 10 / 15 completed. Loss: 514908.015\n",
      "CPU times: user 16min 52s, sys: 1min 15s, total: 18min 7s\n",
      "Wall time: 2min 43s\n",
      "accuracy 0.4334, precision 0.4334, recall 0.4334, f1 0.4334\n",
      "Epoch 11 / 15 completed. Loss: 469367.835\n",
      "CPU times: user 16min 52s, sys: 1min 14s, total: 18min 6s\n",
      "Wall time: 2min 42s\n",
      "accuracy 0.4346, precision 0.4346, recall 0.4346, f1 0.4346\n",
      "Epoch 12 / 15 completed. Loss: 431432.340\n",
      "CPU times: user 16min 47s, sys: 1min 15s, total: 18min 2s\n",
      "Wall time: 2min 43s\n",
      "accuracy 0.4381, precision 0.4381, recall 0.4381, f1 0.4381\n",
      "Epoch 13 / 15 completed. Loss: 399276.056\n",
      "CPU times: user 16min 57s, sys: 1min 15s, total: 18min 13s\n",
      "Wall time: 2min 40s\n",
      "accuracy 0.4397, precision 0.4397, recall 0.4397, f1 0.4397\n",
      "Epoch 14 / 15 completed. Loss: 369900.520\n",
      "CPU times: user 16min 58s, sys: 1min 16s, total: 18min 14s\n",
      "Wall time: 2min 40s\n",
      "accuracy 0.4428, precision 0.4428, recall 0.4428, f1 0.4428\n",
      "Epoch 15 / 15 completed. Loss: 344506.049\n",
      "CPU times: user 16min 44s, sys: 1min 15s, total: 18min\n",
      "Wall time: 2min 42s\n",
      "accuracy 0.4441, precision 0.4441, recall 0.4441, f1 0.4441\n"
     ]
    }
   ],
   "source": [
    "model = baseline_model(x)\n",
    "%time train(x, y, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Your Model\n",
    "\n",
    "Please define in the following cell a function that returns your model.\n",
    "Replace ```[team_name]``` with an pseudonymous name for your team / submission.\n",
    "This name will appear in the ranking.\n",
    "Do not add a softmax layer at the end, since it will be done by the softmax_cross_entropy_with_logits_v2 function later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_[team_name](x):\n",
    "    # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_[team_name](x)\n",
    "train(x, y, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Submission Details\n",
    "\n",
    "* Submission deadline: November 22nd 2018 11:59 p.m.\n",
    "* Submission platform: Uniworx (Übungsblatt \"CIFAR10 Competition\")\n",
    "* Submission content: Submit only the model definition function (```def model_[team_name](x): ...```) in a text file.\n",
    "\n",
    "## Rules:\n",
    "\n",
    "* The model has to be a pure tensorflow model\n",
    "* You may use any tensorflow operations (convolutions, fully-connected layers, mutiplicatoins, ...)\n",
    "* Every model will be trained for 15 epochs\n",
    "* If the training takes more than 8 CPU hours (Intel(R) Core(TM) i7-3770 CPU @ 3.40GHz) your model will be disqualified\n",
    "* If the model uses more than 16 GB of RAM while training (batch_size=1024), it will be disqualified\n",
    "* You may build teams or submit by your own. If you submit as team, please submit your model only once.\n",
    "* You cannot use pre-trained models\n",
    "* Ranking will be with respect to the F1-score\n",
    "\n",
    "## Presentation of Results\n",
    "\n",
    "Results will be presented in the tutorial on November 27th"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
